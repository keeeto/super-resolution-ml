{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/mts87985/ml-tomo/super-resolution-ml/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath= './data/segmentation/train/' #<the root directory of images and masks for training>\n",
    "valpath= './data/segmentation/val/' #<the root directory of images and masks for validation>\n",
    "img_dir= 'noiseless/' # <the subdirectory where images are>\n",
    "mask_dir= 'label/' #<the subdirectory where masks are>\n",
    "ftypes= ['.tiff'] # (<filetypes to look for>) # e.g. ('.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (1280, 1280)\n",
    "patch_shape = (64, 64)\n",
    "patch_range = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handeling.generators import mask_patch_from_file\n",
    "\n",
    "myGene = mask_patch_from_file(datapath,\n",
    "                           img_dir, mask_dir,\n",
    "                           patch_shape, image_shape,\n",
    "                           types = ftypes, patch_range=patch_range,\n",
    "                           debug=False,\n",
    "                           batch_size = 1,\n",
    "                           normalise_images=False)\n",
    "\n",
    "valGene = mask_patch_from_file(valpath,\n",
    "                        img_dir, mask_dir,\n",
    "                        patch_shape, image_shape,\n",
    "                        types = ftypes, patch_range=patch_range,\n",
    "                        debug=False,\n",
    "                        batch_size = 1,\n",
    "                        normalise_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.u_net.model import unet\n",
    "from  models.losses.custom_loss_functions import weighted_cross_entropy\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = unet(input_size = (patch_shape[0], patch_shape[1], 1))\n",
    "opt = Adam(lr=0.01)\n",
    "model.compile(loss=weighted_cross_entropy(1), optimizer=opt,\n",
    "           metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 100 steps\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 0.6083 - accuracy: 0.7077 - val_loss: 0.6733 - val_accuracy: 0.6371\n",
      "Epoch 2/50\n",
      " 34/100 [=========>....................] - ETA: 7s - loss: 0.6047 - accuracy: 0.7087"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "steps_per_epoch = 100\n",
    "model.fit(myGene, steps_per_epoch=steps_per_epoch,\n",
    "          epochs=epochs, validation_data=valGene, validation_steps=100)\n",
    "model.save_weights('saved_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  utils.tools import inference_binary_segmentation\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "datapath = 'data/segmentation/test/noiseless/'\n",
    "patch_shape = (64, 64)\n",
    "image_shape = (1280, 1280)\n",
    "savepath = './inferred_masks/'\n",
    "\n",
    "inference_binary_segmentation(datapath, patch_shape, image_shape, model,\n",
    "                 file_prefix='binary_mask', savepath=savepath, fig_size=(8, 8),\n",
    "                normim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "a = imageio.imread('data/segmentation/train/label/00002.tiff')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
